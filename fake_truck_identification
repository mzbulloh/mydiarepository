
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import datetime
import missingno as msno
from textwrap import wrap
import pandas_gbq
from datetime import datetime
from datetime import timedelta
from scipy.signal import periodogram
import statistics
from sklearn.datasets import make_blobs
from sklearn import cluster

pip install django

!sudo apt install tesseract-ocr
!pip install pytesseract

import shutil
import os
import random
try:
 from PIL import Image
except ImportError:
 import Image

import pytesseract
import cv2
import matplotlib.pyplot as plt
from PIL import Image, ImageEnhance

"""# Export Data From BQ"""

from google.colab import auth
from google.cloud import bigquery
from google.colab import data_table

project = 'logee-data-prod' # Project ID inserted based on the query results selected to explore
location = 'asia-southeast2' # Location inserted based on the query results selected to explore
client = bigquery.Client(project=project, location=location)
data_table.enable_dataframe_formatter()
auth.authenticate_user()

query = '''
SELECT *
FROM `logee-data-prod.L4_lgt.external_logee_vehicles_stnk`
WHERE imageStnkStatus = 'link image'
'''

data=client.query(query=query).to_dataframe()
data

sampel_data = data[1358:1361]
sampel_data

sample_exclusion = data[data["imageStnkLink"].str.contains(".pdf")]
sample_exclusion.head()

# '86cb71e2-b922-4d6c-8c81-c1eb2e1ead5a',
# 'bf918812-f8dc-4029-98cd-2f6326a78bab',
# '60a3db30-852b-4bac-a809-8ef6df6d6c4b',
# 'a148ca6c-573e-47a8-a8e0-4ba1b8540692',
# 'f60f015a-62d2-4de6-b2d0-dcae123c12a3',
# 'fa198c39-8b89-4099-8df1-575136d43ec8',
# '0c6c2de6-d96a-4697-9cdf-597162db1ec4',
# '98901fe7-e299-41cf-9eca-4e71e20db53d',
# '17822a4a-c237-45b6-a06b-8312255f2be3',
# 'da92d210-21d7-4eca-9d1b-9b9db91d65c2',
# '901a347d-163c-4cc4-ba1d-d382b58a05f5',
# '3cf2aa15-f2e5-40f2-8a2b-c61092549160',
# '4e36ebee-0f24-4d09-a777-14b80285e366',
# '8fa84290-24ed-4bd9-b6ce-414584e35a94',
# '3210183f-d760-4e94-93fb-89129c3484ba',
# '21b811b6-8895-4f7e-a3aa-434d9c51766f',
# 'ca01d75e-d5e0-4511-9ebe-25aadd30b43d',
# '50364ce6-b851-4839-8dc8-83f783146f05',
# 'cb5d9bdc-dd6c-46ab-af88-8396aa8d5e4c',
# '219be603-6617-446f-9263-3ad88c028ebd',
# '578ba20b-f9b6-45ab-83b6-494ab2ea71e5',
# '5d644f53-5a0a-4c04-a1a9-c01edd2d931b'

"""# Sample Exclusion"""

df = data

df.loc[df['imageStnkLink'].str.contains('.pdf'),'flag_pdf'] = 'pdf'
df.loc[~df['imageStnkLink'].str.contains('.pdf'),'flag_pdf'] = 'non pdf'

df.loc[df['imageStnkLink'].str.contains('.png'),'flag_png'] = 'png'
df.loc[~df['imageStnkLink'].str.contains('.png'),'flag_png'] = 'non png'

df.loc[df['imageStnkLink'].str.contains('.jpg'),'flag_jpg'] = 'jpg'
df.loc[~df['imageStnkLink'].str.contains('.jpg'),'flag_jpg'] = 'non jpg'

df.groupby('flag_pdf')['vehicleId'].count()

df.groupby('flag_png')['vehicleId'].count()

df.groupby('flag_jpg')['vehicleId'].count()

df.reset_index(inplace=True)
data=df[(df['flag_pdf']=='non pdf')&(df['index']>69553)]
data.head(5)

data.info()

# df.reset_index(inplace=True)
# data=df[(df['flag_pdf']=='non pdf')&(df['index']>1359)]
# data.head(5)

# data.info()

"""# Extract Image"""

# Google Drive Directory
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Google Drive Directory
# %cd /content/drive/My\ Drive/Colab\ Notebooks/google_colab_results_image

pytesseract.pytesseract.tesseract_cmd = (
    r'/usr/bin/tesseract'
)

import requests
import tempfile
from django.core import files

def download_file_from_url(url):
    # Stream the image from the url
    try:
        request = requests.get(url, stream=True)
    except requests.exceptions.RequestException as e:
        # TODO: log error here
        return None

    if request.status_code != requests.codes.ok:
        # TODO: log error here
        return None

    # Create a temporary file
    lf = tempfile.NamedTemporaryFile()

    # Read the streamed image in sections
    for block in request.iter_content(1024 * 8):

        # If no more file then stop
        if not block:
            break

        # Write image block to temporary file
        lf.write(block)

    return files.File(lf)

"""# OCR"""

# data_validity = pd.DataFrame()

# df.reset_index(inplace=True)
# i=550
# data=df[(df['flag_pdf']=='non pdf')&(df['index']>i)]
# list_vehicle = list(data['vehicleId'].unique())
# for j in list_vehicle:
#   vehicle = data[data['vehicleId']==j].reset_index(drop=True)
#   photo = download_file_from_url(vehicle['imageStnkLink'][0])
#   img = ImageEnhance.Contrast(Image.open(photo)).enhance(2)
#   vehicle['words_ocr'] = pytesseract.image_to_string(img.convert('RGB'))
#   data_validity=pd.concat([data_validity,vehicle], ignore_index = True)
#   i=i+1
#   if i%50==0:
#     data_validity.to_csv('data_validity_temp.csv',index=False)
#     pd.DataFrame([i]).to_csv('index_validity.csv')

data_validity = pd.DataFrame()
list_vehicle = list(data['vehicleId'].unique())
i=69553

for j in list_vehicle:

  vehicle = data[data['vehicleId']==j].reset_index(drop=True)

  photo = download_file_from_url(vehicle['imageStnkLink'][0])

  img = Image.open(photo)

  vehicle['words_ocr'] = pytesseract.image_to_string(img.convert('RGB'))

  data_validity=pd.concat([data_validity,vehicle], ignore_index = True)
  i=i+1
  if i%50==0:
    data_validity.to_csv('data_validity_tmp_19.csv',index=False)
    pd.DataFrame([i]).to_csv('index_validity_19.csv')

data_validity.to_csv('data_validity_19.csv')

data_validity.info()

data_validity.head()

"""# Others"""

SHEET_ID = '12s6fZ0allQXkcwjiSeO_tl9VDqiHFqOzyAsxGtjCDxA'
    SHEET_NAME = 'data_validity_1360'
    url = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'
    df1 = pd.read_csv(url)

df1.head()

df1[['vehicleGroupName','policeNum','vehicleGroupName','imageStnkLink','words_ocr']]

"""# Compile Data

"""

data_1 = pd.read_csv('data_validity_1.csv')
data_2 = pd.read_csv('data_validity_2.csv')
data_3 = pd.read_csv('data_validity_3.csv')
data_4 = pd.read_csv('data_validity_4.csv')
data_5 = pd.read_csv('data_validity_5.csv')
data_6 = pd.read_csv('data_validity_6.csv')
data_7 = pd.read_csv('data_validity_7.csv')
data_8 = pd.read_csv('data_validity_8.csv')
data_9 = pd.read_csv('data_validity_9.csv')
data_10 = pd.read_csv('data_validity_10.csv')
data_11 = pd.read_csv('data_validity_11.csv')
data_12 = pd.read_csv('data_validity_12.csv')
data_13 = pd.read_csv('data_validity_13.csv')
data_14 = pd.read_csv('data_validity_14.csv')
data_15 = pd.read_csv('data_validity_15.csv')
data_16 = pd.read_csv('data_validity_16.csv')
data_17 = pd.read_csv('data_validity_17.csv')
data_18 = pd.read_csv('data_validity_18.csv')
data_19 = pd.read_csv('data_validity_19.csv')

data = pd.concat([data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8,data_9,data_10,data_11,data_12,data_13,data_14,data_15,data_16,data_17,data_18,data_19],ignore_index=True)

data.head(5)

data.drop(columns=['flag_png','flag_jpg','Unnamed: 0','index'],inplace=True)
data.drop_duplicates(inplace=True)
data.info()

len(data['vehicleId'].unique())

data.drop(columns=['flag_pdf'],inplace=True)

data.loc[data['imageStnkLink'].str.contains('.pdf'),'flag_pdf'] = 'pdf'
data.loc[~data['imageStnkLink'].str.contains('.pdf'),'flag_pdf'] = 'non pdf'

data.head(5)

data.to_csv('lgt_vehicle_result.csv')

"""# Flagging Output OCR"""

data['words_ocr_norm'] = data['words_ocr'].apply(lambda x: str(x)).map(lambda x: x.replace(" ", ""))

data_flag=pd.DataFrame()
for i in data['policeNum']:
  temp=data[data['policeNum']==i].reset_index(drop=True)
  temp.loc[temp['words_ocr_norm'].str.contains(temp['policeNum'][0],na=False),'flag_policenum'] = 'yes'
  temp.loc[~temp['words_ocr_norm'].str.contains(temp['policeNum'][0],na=False),'flag_policenum'] = 'no'
  data_flag=pd.concat([data_flag,temp], ignore_index = True)

data_flag.info()

data_flag.head()

lib = ['TRUCK','BAK','BOX','CDD','CDE','TRONTON','TRAILER','VAN','FUSO','BARANG','COLT','TRACKTOR','PICK','L300','AEV415P','S401RP','S402RP','NLR55T','GC415V']
data_flag.loc[data_flag['words_ocr_norm'].str.contains('|'.join(lib), na=False),'flag_vehicle'] = 'yes'
data_flag.loc[~data_flag['words_ocr_norm'].str.contains('|'.join(lib), na=False),'flag_vehicle'] = 'no'

data_flag.to_csv('lgt_vehicle_result.csv')

data_flag = pd.read_csv('lgt_vehicle_result_rev_2.csv')

lib = ['TRUCK','BAK','BOX','CDD','CDE','TRONTON','TRAILER','VAN','FUSO','BARANG','COLT','TRACKTOR','PICK','L300','DUMP','INFOKENDARAAN']
data_flag.loc[data_flag['words_ocr_norm'].str.contains('|'.join(lib), na=False),'flag_vehicle_2'] = 'yes'
data_flag.loc[~data_flag['words_ocr_norm'].str.contains('|'.join(lib), na=False),'flag_vehicle_2'] = 'no'

pd.crosstab(data_flag['flag_policenum'],data_flag['flag_vehicle_2'])

pd.crosstab(data_flag['flag_policenum'],data_flag['flag_vehicle_2']).iloc[1,1]/data_flag.shape[0]

(pd.crosstab(data_flag['flag_policenum'],data_flag['flag_vehicle_2']).iloc[0,1]+pd.crosstab(data_flag['flag_policenum'],data_flag['flag_vehicle_2']).iloc[1,1])/data_flag.shape[0]

"""# Back Test"""

data_valid=data_flag[(data_flag['flag_policenum']=='yes')&(data_flag['flag_truck']=='yes')].reset_index()
data_valid.info()

data_valid['imageStnkLink'][0]

data_valid['words_ocr'][0]

data_test=data_flag[(data_flag['flag_policenum']=='yes')&(data_flag['flag_vehicle']=='no')].reset_index()
data_test.info()

data_test['imageStnkLink'][1000]

data_test['policeNum'][90]

data_test['words_ocr'][90]

data_test.loc[data_test['words_ocr'].str.contains('.pdf'),'flag_pdf'] = 'pdf'
data_test.loc[~data_test['words_ocr'].str.contains('.pdf'),'flag_pdf'] = 'non pdf'

"""# OCR Blank"""

ocr_null = data[(data['words_ocr'].isnull())]
ocr_null.info()

ocr_null.tail()

data_flag[data_flag['imageStnkLink']=='https://logee-logee-images-public-prod.oss-ap-southeast-5.aliyuncs.com/logee-trans/vehicle/57575dc2-944a-402d-bf0d-5867033880a0--b71147bc-867b-4fd5-885d-a64b89c14923.png']['words_ocr']

data_test = data_flag[(data_flag['words_ocr'].str.contains("\n"))]
data_test.head()
